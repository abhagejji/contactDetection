{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# import torchvision\n",
    "# from torch.utils.data import DataLoader, Dataset\n",
    "# import pytorch_lightning as pl\n",
    "import pandas as pd\n",
    "# from dataLoader.ShadowDataset import ShadowData, ShadowDatasetTest, ShadowDataset\n",
    "# from transforms.shadowTransforms import ShadowTrainTransforms, shadowValTransforms\n",
    "# from myModels import ResNetModel, MYEfficientNetModel #,EfficientNetModel\n",
    "# from pl_bolts.transforms.dataset_normalizations import(\n",
    "#     imagenet_normalization\n",
    "# )\n",
    "# from pytorch_lightning import Trainer\n",
    "# from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "# from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "# from pytorch_lightning.strategies.ddp import DDPStrategy\n",
    "\n",
    "# from pytorch_lightning.loggers import NeptuneLogger, TensorBoardLogger\n",
    "# import pickle\n",
    "# from pytorch_lightning.profiler import PyTorchProfiler\n",
    "# from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from captum.attr import GuidedGradCam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from myModelsAll import MyEfficientNet_3channel\n",
    "from config import MyTansforms,MyDataset\n",
    "from data_loader import MyDataLoading_color,MyDataLoading_four_channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myModelPath = \"/home/atharva/Abha/Shadows/blender_pipeline/pipeline1/outputModels/model-epoch=09-val_loss=0.35.ckpt\"\n",
    "base_path = \"/panfs/jay/groups/27/kersten/gejji003/Shadows/data/images_rendered_try2/\" # loaction of train test\n",
    "file_path_test = base_path +\"testData.csv\"\n",
    "file_path_train = base_path +\"trainData.csv\"\n",
    "file_path_val = base_path +\"valData.csv\"\n",
    "\n",
    "train_df = pd.read_csv(file_path_train)\n",
    "val_df = pd.read_csv(file_path_val)\n",
    "test_df = pd.read_csv(file_path_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theDataLoader = MyDataLoading_color\n",
    "color_channel = \"colors\"\n",
    "shadow_channel = \"cast_shadow\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = MyEfficientNet_3channel.load_from_checkpoint(myModelPath)\n",
    "model.eval()\n",
    "model.cuda()\n",
    "\n",
    "dataset = MyDataset(train_df,val_df,test_df,color_channel,shadow_channel,theDataLoader)\n",
    "test_loader = dataset.test_dataloader()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_conv_layer = None\n",
    "myGradcam = GuidedGradCam(model, last_conv_layer)\n",
    "y_all = []\n",
    "pred_all = []\n",
    "with torch.no_grad():\n",
    "    pbar = tqdm(enumerate(test_loader), total=len(test_loader))\n",
    "    for idx, X in pbar:\n",
    "        X, y = X\n",
    "        X = X.cuda().contiguous()\n",
    "        # print(\"TYPE X: \", type(X))\n",
    "        # y = y.cuda()\n",
    "        myPred = model(X).squeeze().cuda()\n",
    "        myPred = myPred.cpu()\n",
    "        print(myPred)\n",
    "        # print(myPred)\n",
    "        # if myPred > 0.08:\n",
    "        #     myPred = 1\n",
    "        # else:\n",
    "        #     myPred = 0\n",
    "        myPred = np.argmax(myPred)\n",
    "        myAttr = myGradcam.attribute(X, myPred)           \n",
    "        # print(type(myPred))\n",
    "        # y = y.cuda()\n",
    "        # print(type(y))\n",
    "        # print(y)\n",
    "        y_all.append(y.int().numpy())\n",
    "        # print(myPred)\n",
    "        pred_all.append(myPred)\n",
    "    myClassRep = classification_report(y_all, pred_all)\n",
    "    print(myClassRep)\n",
    "    myConfMat = confusion_matrix(y_all, pred_all)\n",
    "    print(myConfMat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(myModelPath, myCSVPath, myBatchSize, myNumWorkers):\n",
    "    model = MYEfficientNetModel.load_from_checkpoint(myModelPath)\n",
    "    model.eval()\n",
    "    model.cuda()\n",
    "\n",
    "    df_test = pd.read_csv(myCSVPath)\n",
    "# df=self.dfTest, mount_point=self.mountPoint, label=self.label, img_col=self.img_path, color=self.color, transform=self.valid_transform\n",
    "    test_ds = ShadowDataset(df=df_test, img_col=\"path_to_img\", label=\"label\", color=\"colors\", shadowMask= \"cast_shadow\", mount_point=\"./\", depth=\"depth\", transform=shadowValTransforms)\n",
    "\n",
    "    test_loader = DataLoader(test_ds, batch_size=myBatchSize, shuffle=False, num_workers=myNumWorkers, pin_memory=True, prefetch_factor=4)\n",
    "    last_conv_layer = None\n",
    "    myGradcam = GuidedGradCam(model, last_conv_layer)\n",
    "    y_all = []\n",
    "    pred_all = []\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(enumerate(test_loader), total=len(test_loader))\n",
    "        for idx, X in pbar:\n",
    "            X, y = X\n",
    "            X = X.cuda().contiguous()\n",
    "            # print(\"TYPE X: \", type(X))\n",
    "            # y = y.cuda()\n",
    "            myPred = model(X).squeeze().cuda()\n",
    "            myPred = myPred.cpu()\n",
    "            print(myPred)\n",
    "            # print(myPred)\n",
    "            # if myPred > 0.08:\n",
    "            #     myPred = 1\n",
    "            # else:\n",
    "            #     myPred = 0\n",
    "            myPred = np.argmax(myPred)\n",
    "            myAttr = myGradcam.attribute(X, myPred)           \n",
    "            # print(type(myPred))\n",
    "            # y = y.cuda()\n",
    "            # print(type(y))\n",
    "            # print(y)\n",
    "            y_all.append(y.int().numpy())\n",
    "            # print(myPred)\n",
    "            pred_all.append(myPred)\n",
    "            # print(y_all)\n",
    "            # print(pred_all)\n",
    "        \n",
    "        myClassRep = classification_report(y_all, pred_all)\n",
    "        print(myClassRep)\n",
    "        myConfMat = confusion_matrix(y_all, pred_all)\n",
    "        print(myConfMat)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # myModelPath = \"/home/atharva/Abha/Shadows/blender_pipeline/pipeline1/outputModels/epoch=3-val_loss=0.6943.ckpt\"\n",
    "    # myModelPath = \"/home/atharva/Abha/Shadows/blender_pipeline/pipeline1/outputModels/model-epoch=11-val_loss=0.34.ckpt\"\n",
    "    myModelPath = \"/home/atharva/Abha/Shadows/blender_pipeline/pipeline1/outputModels/model-epoch=09-val_loss=0.35.ckpt\"\n",
    "    myCSVPath = \"/home/atharva/Abha/Shadows/blender_pipeline/pipeline1/dataFiles/testData.csv\"\n",
    "    myBatchSize = 1\n",
    "    myNumWorkers = 4\n",
    "    main(myModelPath, myCSVPath, myBatchSize, myNumWorkers)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
